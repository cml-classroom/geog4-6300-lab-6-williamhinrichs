---
title: 'Geog6300: Lab 6'
output: github_document
editor_options: 
  chunk_output_type: console
---
{Name: William Hinrichs}

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Regression

```{r setup, message=FALSE, warning=FALSE}
library(sf)
library(tidyverse)
library(tmap)
library(car)
```

**Overview:**
This lab focuses on regression techniques. You'll be analyzing the association of various physical and climatological characteristics in Australia with observations of several animals recorded on the citizen science app iNaturalist.

###Data and research questions###

Let's import the dataset.

```{r}
lab6_data<-st_read("data/aus_climate_inat.gpkg")
```

The dataset for this lab is a 1 decimal degree hexagon grid that has aggregate statistics for a number of variables:

* ndvi: NDVI/vegetation index values from Landsat data (via Google Earth Engine). These values range from -1 to 1, with higher values indicating more vegetation.
* maxtemp_00/20_med: Median maximum temperature (C) in 2000 or 2020 (data from SILO/Queensland government)
* mintemp_00/20_med: Median minimum temperature (C) in 2020 or 2020 (data from SILO/Queensland government)
* rain_00/20_sum: Total rainfall (mm) in 2000 or 2020 (data from SILO/Queensland government)
* pop_00/20: Total population in 2000 or 2020 (data from NASA's Gridded Population of the World)
* water_00/20_pct: Percentage of land covered by water at some point during the year in 2000 or 2020
* elev_med: Median elevation (meters) (data from the Shuttle Radar Topography Mission/NASA)

There are also observation counts from iNaturalist for several distinctively Australian animal species: the central bearded dragon, the common emu, the red kangaroo, the agile wallaby, the laughing kookaburra, the wombat, the koala, and the platypus.

Our primary research question is how the climatological/physical variables in our dataset are predictive of the NDVI value. We will build models for 2020 as well as the change from 2000 to 2020. The second is referred to as a "first difference" model and can sometimes be more useful for identifying causal mechanisms.

###Part 1: Analysis of 2020 data###

We will start by looking at data for 2020. 

**Question 1** _Create histograms for NDVI, max temp., min temp., rain, and population, and water in 2020 as well as elevation. Based on these graphs, assess the normality of these variables._

```{r}
#Code goes here
variables <- c("ndvi_20_med", "maxtemp_20_med", "mintemp_20_med", "rain_20_sum", "pop_20", "water_20_pct", "elev_med")

for (var in variables) {
  hist(lab6_data[[var]], main = paste("Histogram of", var), xlab = var, col = "lightblue", breaks = 30)}


```

{most of the variables do not follow a normal distribution. elevaton temps are closer to normality but still show a skew. rainfall, poulation and water percentage are the most skewed with significant deviations from normality.transformations might help normalize some of these variables if needed.}

**Question 2** _Use tmap to map these same variables using Jenks natural breaks as the classification method. For an extra challenge, use `tmap_arrange` to plot all maps in a single figure._

```{r}
tm_list <- lapply(variables, function(var) {
  tm_shape(lab6_data) +
    tm_polygons(var, style = "jenks", palette = "viridis", title = var) +
    tm_layout(
      title = paste("Map of", var),
      title.position = c("center", "top"),  
      legend.outside = TRUE,               
      legend.outside.position = "right",
      legend.frame = TRUE)})


tmap_arrange(plotlist = tm_list)

```


**Question 3** _Based on the maps from question 3, summarise major patterns you see in the spatial distribution of these data from any of your variables of interest. How do they appear to be associated with the NDVI variable?_

{rainfall, water pct, and moderate temperatures are positively associated with higher NDVI values.those factors indicate favorable conditions for vegetation growth. high max temp and low rainfall areas in central and western correspond to lower NDVI, highlighting the impact of arrid conditions.population density does not have a clear relationship with NDVI , as urban areas reduce vegetation irrespective of climate.}

**Question 4** _Create univariate models for each of the variables listed in question 1, with NDVI in 2020 as the dependent variable. Print a summary of each model. Write a summary of those results that indicates the direction, magnitude, and significance for each model coefficient._

```{r}
results <- lapply(variables, function(var) {
  model <- lm(ndvi_20_med ~ lab6_data[[var]], data = lab6_data)
  summary(model)})
results
```

{most are highly significant with a p value of p<0.001, except for 6, where the value is not statistically significant at p<0.249. 4,5,7 indicate the independent variable has minimal impact on NDVI. The highest explanatory power is observed in 4(42.73%), and the lowest is 6 with 0.186%. 1,4,5,and 6 have positive effects, however, 2,3,6 have negative effects.}

**Question 5** _Create a multivariate regression model with the variables of interest, choosing EITHER max or min temperature (but not both) You may also choose to leave out any variables that were insignificant in Q4. Use the univariate models as your guide. Call the results._

```{r}
#Code goes here
multi_model <- lm(ndvi_20_med ~ maxtemp_20_med + rain_20_sum + pop_20 + water_20_pct + elev_med, data = lab6_data)
summary(multi_model)
```

**Question 6** _Summarize the results of the multivariate model. What are the direction, magnitude, and significance of each coefficient? How did it change from the univariate models you created in Q4 (if at all)? What do the R2 and F-statistic values tell you about overall model fit?_

{The model provides a substantial portion of the variance in NDVI.the high R value (0.6397 adjusted 0.6372) and the F statistic (252.1 on 5 and 710 DF) suggest that chosen predictors are appropriate for modeling NDVI. 
1.intercept - estimate is 0.4591, the interpretation is when all independent variables are at 0, the NDVI is predicted to be 0.4591. the significance is highly significant with p<2x10e-16
2. maxtemp_20_med - Direction is negative, magnitude is a 1 degree C increase in max temp is associated with a -0.01173 decrease in NDVI. the significance is highly significant (p< 2x10e-16
3.Rain_20_sum - Direction is positive, magnitude is 8.464x10e-7, which rainfall is associated with a slight increase in NDVI. the significance is highly significant with a value od p<2x10e-16.
4.pop_20 - Direction is positive, magnitude is 2.873x10e-7 which a one person increase in population is associated with a small increase in NDVI. Significance is significant with p=0.00613
5.water_20_pct - Direction is negative, magnitude is -0.03387, which an increase in water coverage is associated with a decrease in NDVI. Significance is not significant with p=0.7275.
6.elev_med - Direction is positive, magnitude is 0.0001215 with an increase in elevation is associated with a small increase in NDVI. significance is highly significant with p-1.28x10e-10.}

**Question 7** _Use a histogram and a map to assess the normality of residuals and any spatial autocorrelation. Summarise any notable patterns that you see._

```{r}
#Code goes here
lab6_data$residuals <- residuals(multi_model)

residuals <- as.numeric(residuals(multi_model))

hist(residuals, main = "Histogram of Residuals", xlab = "Residuals", col = "lightblue", breaks = 30)

tm_shape(lab6_data) +
  tm_polygons("residuals", style = "jenks", palette = "RdBu", midpoint = 0, title = "Residuals") +
  tm_layout(
    title = "Map of Residuals",
    title.position = c("center", "top"),
    legend.outside = TRUE,
    legend.outside.position = "right",
    legend.frame = TRUE)
```

{The residuals are generally symmetric and centered around zero, indicating a good overall mode fit. However, there are slight deviations from normality, with a longer left tail and a few outliers on both extremes. These outliers suggest the model may struggle with extreme cases, but the concentration of residuals near zero reflects strong performance for most observations}

**Question 8** _Assess any issues with multicollinearity or heteroskedastity in this model using the techniques shown in class. Run the appropriate tests and explain what their results show you._

```{r}
#Code goes here
vif(multi_model)

ncvTest(multi_model)
```

{the values are between 1.08 and 1.17, which are wll below the typical threshold that indicates potential multicollinearity, which is not a concern in this model, as the predictors are not strongly correlated with eachother. the ncvtect has a chi square test value of 287.39. the DF is 1 and the p value is p<2.22x10e-16, indicating a highly significant result. the test identifies a violation of the homoscedasticity assumption, meaning the variance of the residuals is not constant across fitted values. this suggests heteroskedasicity in the model.}

**Question 9** _How would you summarise the results of this model in a sentence or two? In addition, looking at the full model and your diagnostics, do you feel this is a model that provides meaningful results? Explain your answer._
 
{Yes, the model provides meaningful results as it captures key predictors of NDVI and explains a substantial portion of the variance. However, the heteroskedasticity issue highlights potential limitations with the reliability of standard errors and significance tests. Adjustments, such as using robust standard errors or alternative models, could enhance its interpretability and validity.}

**Disclosure of assistance:** _Besides class materials, what other sources of assistance did you use while completing this lab? These can include input from classmates, relevant material identified through web searches (e.g., Stack Overflow), or assistance from ChatGPT or other AI tools. How did these sources support your own learning in completing this lab?_

{I was having issues with creating the histogram for the residuals and kept getting a figure margins too large warning. i used ChatGPT for a reference code to figure out why the residuals were not coming up in my lab6_data so i could make a histogram. I saw the residuals were not in the df, and made the adjustments after looking at both the code and the df. I used additional references such as CRAN and a couple work colleagues which are data scientists to check my work. The individuals at work helped me change a couple parts of question 7 i was having issues with. I also used chatGPT to check some parts of my code that I had issues with, and had one or two small things, like a simple mistype such as a misspelling and a capital letter where it did not need to be. using all these references have helped my with my work but start working on projects for my research topic as well. I also see that peers with more experience helped me more with this lab, and helped me see that chatGPT may be a decent reference, but using peers with years of experience can be more reliable.}

**Lab reflection:** _How do you feel about the work you did on this lab? Was it easy, moderate, or hard? What were the biggest things you learned by completing it?_

{This lab was quite challenging, but I managed to complete it. It was moderate with a few hard parts, which to me is good. I learned the regression techniques is one thing I will definitely need to do more to become more familiar with the results and how other results factor into my work.}


**Challenge question**

#Option 1
Create a first difference model. To do that, subtract the values in 2000 from the values in 2020 for each variable for which that is appropriate. Then create a new model similar to the one you created in question 5, but using these new variables showing the *change in values* over time. Call the results of the model, and interpret the results in the same ways you did above. Also chart and map the residuals to assess model error. Finally, write a short section that summarises what, if anything, this model tells you. 

```{r}

```




#Option 2
The animal data included in this dataset is an example of count data, and usually we would use a Poisson or similar model for that purpose. Let's try it with regular OLS regression though. Create two regression models to assess how the counts of two different animals (say, koalas and emus) are associated with at least three of the environmental/climatological variables given above. Be sure to use the same independent variables in each model. Interpret the results of each model and then explain the importance of any differences in the model coefficients between them, focusing on direction, magnitude, and significance.

```{r}
Koala_model <- lm(Koala ~ maxtemp_20_med + rain_20_sum + pop_20, data = lab6_data)
wombat_model <- lm(Wombat ~ maxtemp_20_med + rain_20_sum + pop_20, data = lab6_data)

summary(Koala_model)
summary(wombat_model)


```
{Both models show a positive association. between population density and animal counts. rainfall a positive effect in both models, but the effect is significant for wombats but not for koalas. the magnitude for koalas is stronger for koalas (0.002644) compared to wombats (0.0004588). the rainfall has a stronger impact on wombat counts than the koala counts as well. the coefficient for the wombats is 1.634x10e-4. wombats counts are influenced significantly all three predictors (max temp, rainfall and population). koalas are only significantly influenced only by population. Overall, the differences highlight the distinct ecological and environmental factors influencing koalas and wombats, emphasizing the need for species-specific conservation strategies.}
